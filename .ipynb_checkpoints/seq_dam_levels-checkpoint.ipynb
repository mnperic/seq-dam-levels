{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "2ca79484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies and setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.dates as matplotlibdates\n",
    "from matplotlib.dates import date2num\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "0db662c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>5/03/2017</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>6/03/2017</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>7/03/2017</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>8/03/2017</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>28/02/2022</td>\n",
       "      <td>107.5</td>\n",
       "      <td>32686.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>1/03/2022</td>\n",
       "      <td>104.1</td>\n",
       "      <td>31656.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2/03/2022</td>\n",
       "      <td>102.7</td>\n",
       "      <td>31223.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>3/03/2022</td>\n",
       "      <td>103.0</td>\n",
       "      <td>31324.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>4/03/2022</td>\n",
       "      <td>102.4</td>\n",
       "      <td>31117.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name        Date  Last Observation (%)  Last Observation (ML)\n",
       "0     Atkinson   4/03/2017                   5.4                1655.39\n",
       "1     Atkinson   5/03/2017                   5.4                1655.39\n",
       "2     Atkinson   6/03/2017                   5.4                1655.39\n",
       "3     Atkinson   7/03/2017                   5.4                1655.39\n",
       "4     Atkinson   8/03/2017                   5.4                1655.39\n",
       "...        ...         ...                   ...                    ...\n",
       "1816  Atkinson  28/02/2022                 107.5               32686.23\n",
       "1817  Atkinson   1/03/2022                 104.1               31656.60\n",
       "1818  Atkinson   2/03/2022                 102.7               31223.76\n",
       "1819  Atkinson   3/03/2022                 103.0               31324.52\n",
       "1820  Atkinson   4/03/2022                 102.4               31117.77\n",
       "\n",
       "[1821 rows x 4 columns]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read individual csv files and store as DataFrames\n",
    "\n",
    "atkinson_path = \"Resources/dam_levels/atkinson.csv\"\n",
    "atkinson_df = pd.read_csv(atkinson_path)\n",
    "\n",
    "baroon_pocket_path = \"Resources/dam_levels/baroon_pocket.csv\"\n",
    "baroon_pocket_df = pd.read_csv(baroon_pocket_path)\n",
    "\n",
    "bill_gunn_path = \"Resources/dam_levels/bill_gunn.csv\"\n",
    "bill_gunn_df = pd.read_csv(bill_gunn_path)\n",
    "\n",
    "borumba_path = \"Resources/dam_levels/borumba.csv\"\n",
    "borumba_df = pd.read_csv(borumba_path)\n",
    "\n",
    "cedar_pocket_path = \"Resources/dam_levels/cedar_pocket.csv\"\n",
    "cedar_pocket_df = pd.read_csv(cedar_pocket_path)\n",
    "\n",
    "clarendon_path = \"Resources/dam_levels/clarendon.csv\"\n",
    "clarendon_df = pd.read_csv(clarendon_path)\n",
    "\n",
    "cooloolabin_path = \"Resources/dam_levels/cooloolabin.csv\"\n",
    "cooloolabin_df = pd.read_csv(cooloolabin_path)\n",
    "\n",
    "enoggera_path = \"Resources/dam_levels/enoggera.csv\"\n",
    "enoggera_df = pd.read_csv(enoggera_path)\n",
    "\n",
    "ewen_maddock_path = \"Resources/dam_levels/ewen_maddock.csv\"\n",
    "ewen_maddock_df = pd.read_csv(ewen_maddock_path)\n",
    "\n",
    "gold_creek_path = \"Resources/dam_levels/gold_creek.csv\"\n",
    "gold_creek_df = pd.read_csv(gold_creek_path)\n",
    "\n",
    "hinze_path = \"Resources/dam_levels/hinze.csv\"\n",
    "hinze_df = pd.read_csv(hinze_path)\n",
    "\n",
    "lake_kurwongbah_path = \"Resources/dam_levels/lake_kurwongbah.csv\"\n",
    "lake_kurwongbah_df = pd.read_csv(lake_kurwongbah_path)\n",
    "\n",
    "lake_macdonald_path = \"Resources/dam_levels/lake_macdonald.csv\"\n",
    "lake_macdonald_df = pd.read_csv(lake_macdonald_path)\n",
    "\n",
    "lake_manchester_path = \"Resources/dam_levels/lake_manchester.csv\"\n",
    "lake_manchester_df = pd.read_csv(lake_manchester_path)\n",
    "\n",
    "lake_samsonvale_path = \"Resources/dam_levels/lake_samsonvale.csv\"\n",
    "lake_samsonvale_df = pd.read_csv(lake_samsonvale_path)\n",
    "\n",
    "leslie_harrison_path = \"Resources/dam_levels/leslie_harrison.csv\"\n",
    "leslie_harrison_df = pd.read_csv(leslie_harrison_path)\n",
    "\n",
    "little_nerang_path = \"Resources/dam_levels/little_nerang.csv\"\n",
    "little_nerang_df = pd.read_csv(little_nerang_path)\n",
    "\n",
    "maroon_path = \"Resources/dam_levels/maroon.csv\"\n",
    "maroon_df = pd.read_csv(maroon_path)\n",
    "\n",
    "moogerah_path = \"Resources/dam_levels/moogerah.csv\"\n",
    "moogerah_df = pd.read_csv(moogerah_path)\n",
    "\n",
    "nindooinbah_path = \"Resources/dam_levels/nindooinbah.csv\"\n",
    "nindooinbah_df = pd.read_csv(nindooinbah_path)\n",
    "\n",
    "poona_path = \"Resources/dam_levels/poona.csv\"\n",
    "poona_df = pd.read_csv(poona_path)\n",
    "\n",
    "seq_water_grid_path = \"Resources/dam_levels/seq_water_grid.csv\"\n",
    "seq_water_grid_df = pd.read_csv(seq_water_grid_path)\n",
    "\n",
    "somerset_path = \"Resources/dam_levels/somerset.csv\"\n",
    "somerset_df = pd.read_csv(somerset_path)\n",
    "\n",
    "wappa_path = \"Resources/dam_levels/wappa.csv\"\n",
    "wappa_df = pd.read_csv(wappa_path)\n",
    "\n",
    "wivenhoe_path = \"Resources/dam_levels/wivenhoe.csv\"\n",
    "wivenhoe_df = pd.read_csv(wivenhoe_path)\n",
    "\n",
    "wyaralong_path = \"Resources/dam_levels/wyaralong.csv\"\n",
    "wyaralong_df = pd.read_csv(wyaralong_path)\n",
    "\n",
    "alderley_rainfall_path = \"Resources/rainfall/alderley_rainfall.csv\"\n",
    "alderley_df = pd.read_csv(alderley_rainfall_path)\n",
    "\n",
    "brisbane_rainfall_path = \"Resources/rainfall/brisbane_rainfall.csv\"\n",
    "brisbane_df = pd.read_csv(brisbane_rainfall_path)\n",
    "\n",
    "dam_locations_path = \"Resources/dam_locations.csv\"\n",
    "dam_locations_df = pd.read_csv(dam_locations_path)\n",
    "\n",
    "atkinson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "28e178d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-03-04</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>107.5</td>\n",
       "      <td>32686.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>104.1</td>\n",
       "      <td>31656.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>102.7</td>\n",
       "      <td>31223.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>103.0</td>\n",
       "      <td>31324.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>102.4</td>\n",
       "      <td>31117.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name       Date  Last Observation (%)  Last Observation (ML)\n",
       "0     Atkinson 2017-03-04                   5.4                1655.39\n",
       "1     Atkinson 2017-03-05                   5.4                1655.39\n",
       "2     Atkinson 2017-03-06                   5.4                1655.39\n",
       "3     Atkinson 2017-03-07                   5.4                1655.39\n",
       "4     Atkinson 2017-03-08                   5.4                1655.39\n",
       "...        ...        ...                   ...                    ...\n",
       "1816  Atkinson 2022-02-28                 107.5               32686.23\n",
       "1817  Atkinson 2022-03-01                 104.1               31656.60\n",
       "1818  Atkinson 2022-03-02                 102.7               31223.76\n",
       "1819  Atkinson 2022-03-03                 103.0               31324.52\n",
       "1820  Atkinson 2022-03-04                 102.4               31117.77\n",
       "\n",
       "[1821 rows x 4 columns]"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' columns in all .csvs to datetime\n",
    "\n",
    "atkinson_df['Date'] = pd.to_datetime(atkinson_df['Date'], format=\"%d/%m/%Y\")\n",
    "baroon_pocket_df['Date'] = pd.to_datetime(baroon_pocket_df['Date'], format=\"%d/%m/%Y\")\n",
    "bill_gunn_df['Date'] = pd.to_datetime(bill_gunn_df['Date'], format=\"%d/%m/%Y\")\n",
    "borumba_df['Date'] = pd.to_datetime(borumba_df['Date'], format=\"%d/%m/%Y\")\n",
    "cedar_pocket_df['Date'] = pd.to_datetime(cedar_pocket_df['Date'], format=\"%d/%m/%Y\")\n",
    "clarendon_df['Date'] = pd.to_datetime(clarendon_df['Date'], format=\"%d/%m/%Y\")\n",
    "cooloolabin_df['Date'] = pd.to_datetime(cooloolabin_df['Date'], format=\"%d/%m/%Y\")\n",
    "enoggera_df['Date'] = pd.to_datetime(enoggera_df['Date'], format=\"%d/%m/%Y\")\n",
    "ewen_maddock_df['Date'] = pd.to_datetime(ewen_maddock_df['Date'], format=\"%d/%m/%Y\")\n",
    "gold_creek_df['Date'] = pd.to_datetime(gold_creek_df['Date'], format=\"%d/%m/%Y\")\n",
    "hinze_df['Date'] = pd.to_datetime(hinze_df['Date'], format=\"%d/%m/%Y\")\n",
    "lake_kurwongbah_df['Date'] = pd.to_datetime(lake_kurwongbah_df['Date'], format=\"%d/%m/%Y\")\n",
    "lake_macdonald_df['Date'] = pd.to_datetime(lake_macdonald_df['Date'], format=\"%d/%m/%Y\")\n",
    "lake_manchester_df['Date'] = pd.to_datetime(lake_manchester_df['Date'], format=\"%d/%m/%Y\")\n",
    "lake_samsonvale_df['Date'] = pd.to_datetime(lake_samsonvale_df['Date'], format=\"%d/%m/%Y\")\n",
    "leslie_harrison_df['Date'] = pd.to_datetime(leslie_harrison_df['Date'], format=\"%d/%m/%Y\")\n",
    "little_nerang_df['Date'] = pd.to_datetime(little_nerang_df['Date'], format=\"%d/%m/%Y\")\n",
    "maroon_df['Date'] = pd.to_datetime(maroon_df['Date'], format=\"%d/%m/%Y\")\n",
    "moogerah_df['Date'] = pd.to_datetime(moogerah_df['Date'], format=\"%d/%m/%Y\")\n",
    "nindooinbah_df['Date'] = pd.to_datetime(nindooinbah_df['Date'], format=\"%d/%m/%Y\")\n",
    "poona_df['Date'] = pd.to_datetime(poona_df['Date'], format=\"%d/%m/%Y\")\n",
    "seq_water_grid_df['Date'] = pd.to_datetime(seq_water_grid_df['Date'], format=\"%d/%m/%Y\")\n",
    "somerset_df['Date'] = pd.to_datetime(somerset_df['Date'], format=\"%d/%m/%Y\")\n",
    "wappa_df['Date'] = pd.to_datetime(wappa_df['Date'], format=\"%d/%m/%Y\")\n",
    "somerset_df['Date'] = pd.to_datetime(somerset_df['Date'], format=\"%d/%m/%Y\")\n",
    "wivenhoe_df['Date'] = pd.to_datetime(wivenhoe_df['Date'], format=\"%d/%m/%Y\")\n",
    "wyaralong_df['Date'] = pd.to_datetime(wyaralong_df['Date'], format=\"%d/%m/%Y\")\n",
    "\n",
    "atkinson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "4e5abf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4296619.85"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total 'Last Observation (ML)' for each dam + SEQ Water Grid\n",
    "\n",
    "atkinson_total_ML = atkinson_df['Last Observation (ML)'].sum()\n",
    "baroon_pocket_total_ML = baroon_pocket_df['Last Observation (ML)'].sum()\n",
    "bill_gunn_total_ML = bill_gunn_df['Last Observation (ML)'].sum()\n",
    "borumba_total_ML = borumba_df['Last Observation (ML)'].sum()\n",
    "cedar_pocket_total_ML = cedar_pocket_df['Last Observation (ML)'].sum()\n",
    "clarendon_total_ML = clarendon_df['Last Observation (ML)'].sum()\n",
    "cooloolabin_total_ML = cooloolabin_df['Last Observation (ML)'].sum()\n",
    "enoggera_total_ML = enoggera_df['Last Observation (ML)'].sum()\n",
    "ewen_maddock_total_ML = ewen_maddock_df['Last Observation (ML)'].sum()\n",
    "gold_creek_total_ML = gold_creek_df['Last Observation (ML)'].sum()\n",
    "hinze_total_ML = hinze_df['Last Observation (ML)'].sum()\n",
    "lake_kurwongbah_total_ML = lake_kurwongbah_df['Last Observation (ML)'].sum()\n",
    "lake_macdonald_total_ML = lake_macdonald_df['Last Observation (ML)'].sum()\n",
    "lake_manchester_total_ML = lake_manchester_df['Last Observation (ML)'].sum()\n",
    "lake_samsonvale_total_ML = lake_samsonvale_df['Last Observation (ML)'].sum()\n",
    "leslie_harrison_total_ML = leslie_harrison_df['Last Observation (ML)'].sum()\n",
    "little_nerang_total_ML = little_nerang_df['Last Observation (ML)'].sum()\n",
    "maroon_total_ML = maroon_df['Last Observation (ML)'].sum()\n",
    "moogerah_total_ML = moogerah_df['Last Observation (ML)'].sum()\n",
    "nindooinbah_total_ML = nindooinbah_df['Last Observation (ML)'].sum()\n",
    "poona_total_ML = poona_df['Last Observation (ML)'].sum()\n",
    "seq_water_grid_total_ML = seq_water_grid_df['Last Observation (ML)'].sum()\n",
    "somerset_total_ML = somerset_df['Last Observation (ML)'].sum()\n",
    "wappa_total_ML = wappa_df['Last Observation (ML)'].sum()\n",
    "wivenhoe_total_ML = wivenhoe_df['Last Observation (ML)'].sum()\n",
    "wyaralong_total_ML = wyaralong_df['Last Observation (ML)'].sum()\n",
    "\n",
    "atkinson_total_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "8d1be1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359.4837177375207"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of 'Last Observation (ML)' for each dam + SEQ Water Grid\n",
    "\n",
    "atkinson_avg_ML = atkinson_df['Last Observation (ML)'].mean()\n",
    "baroon_pocket_avg_ML = baroon_pocket_df['Last Observation (ML)'].mean()\n",
    "bill_gunn_avg_ML = bill_gunn_df['Last Observation (ML)'].mean()\n",
    "borumba_avg_ML = borumba_df['Last Observation (ML)'].mean()\n",
    "cedar_pocket_avg_ML = cedar_pocket_df['Last Observation (ML)'].mean()\n",
    "clarendon_avg_ML = clarendon_df['Last Observation (ML)'].mean()\n",
    "cooloolabin_avg_ML = cooloolabin_df['Last Observation (ML)'].mean()\n",
    "enoggera_avg_ML = enoggera_df['Last Observation (ML)'].mean()\n",
    "ewen_maddock_avg_ML = ewen_maddock_df['Last Observation (ML)'].mean()\n",
    "gold_creek_avg_ML = gold_creek_df['Last Observation (ML)'].mean()\n",
    "hinze_avg_ML = hinze_df['Last Observation (ML)'].mean()\n",
    "lake_kurwongbah_avg_ML = lake_kurwongbah_df['Last Observation (ML)'].mean()\n",
    "lake_macdonald_avg_ML = lake_macdonald_df['Last Observation (ML)'].mean()\n",
    "lake_manchester_avg_ML = lake_manchester_df['Last Observation (ML)'].mean()\n",
    "lake_samsonvale_avg_ML = lake_samsonvale_df['Last Observation (ML)'].mean()\n",
    "leslie_harrison_avg_ML = leslie_harrison_df['Last Observation (ML)'].mean()\n",
    "little_nerang_avg_ML = little_nerang_df['Last Observation (ML)'].mean()\n",
    "maroon_avg_ML = maroon_df['Last Observation (ML)'].mean()\n",
    "moogerah_avg_ML = moogerah_df['Last Observation (ML)'].mean()\n",
    "nindooinbah_avg_ML = nindooinbah_df['Last Observation (ML)'].mean()\n",
    "poona_avg_ML = poona_df['Last Observation (ML)'].mean()\n",
    "seq_water_grid_avg_ML = seq_water_grid_df['Last Observation (ML)'].mean()\n",
    "somerset_avg_ML = somerset_df['Last Observation (ML)'].mean()\n",
    "wappa_avg_ML = wappa_df['Last Observation (ML)'].mean()\n",
    "wivenhoe_avg_ML = wivenhoe_df['Last Observation (ML)'].mean()\n",
    "wyaralong_avg_ML = wyaralong_df['Last Observation (ML)'].mean()\n",
    "\n",
    "atkinson_avg_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "e765b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.766392092256835"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of 'Last Observation (%)' for each dam + SEQ Water Grid\n",
    "\n",
    "atkinson_avg_percent = atkinson_df['Last Observation (%)'].mean()\n",
    "baroon_pocket_avg_percent = baroon_pocket_df['Last Observation (%)'].mean()\n",
    "bill_gunn_avg_percent = bill_gunn_df['Last Observation (%)'].mean()\n",
    "borumba_avg_percent = borumba_df['Last Observation (%)'].mean()\n",
    "cedar_pocket_avg_percent = cedar_pocket_df['Last Observation (%)'].mean()\n",
    "clarendon_avg_percent = clarendon_df['Last Observation (%)'].mean()\n",
    "cooloolabin_avg_percent = cooloolabin_df['Last Observation (%)'].mean()\n",
    "enoggera_avg_percent = enoggera_df['Last Observation (%)'].mean()\n",
    "ewen_maddock_avg_percent = ewen_maddock_df['Last Observation (%)'].mean()\n",
    "gold_creek_avg_percent = gold_creek_df['Last Observation (%)'].mean()\n",
    "hinze_avg_percent = hinze_df['Last Observation (%)'].mean()\n",
    "lake_kurwongbah_avg_percent = lake_kurwongbah_df['Last Observation (%)'].mean()\n",
    "lake_macdonald_avg_percent = lake_macdonald_df['Last Observation (%)'].mean()\n",
    "lake_manchester_avg_percent = lake_manchester_df['Last Observation (%)'].mean()\n",
    "lake_samsonvale_avg_percent = lake_samsonvale_df['Last Observation (%)'].mean()\n",
    "leslie_harrison_avg_percent = leslie_harrison_df['Last Observation (%)'].mean()\n",
    "little_nerang_avg_percent = little_nerang_df['Last Observation (%)'].mean()\n",
    "maroon_avg_percent = maroon_df['Last Observation (%)'].mean()\n",
    "moogerah_avg_percent = moogerah_df['Last Observation (%)'].mean()\n",
    "nindooinbah_avg_percent = nindooinbah_df['Last Observation (%)'].mean()\n",
    "poona_avg_percent = poona_df['Last Observation (%)'].mean()\n",
    "seq_water_grid_avg_percent = seq_water_grid_df['Last Observation (%)'].mean()\n",
    "somerset_avg_percent = somerset_df['Last Observation (%)'].mean()\n",
    "wappa_avg_percent = wappa_df['Last Observation (%)'].mean()\n",
    "wivenhoe_avg_percent = wivenhoe_df['Last Observation (%)'].mean()\n",
    "wyaralong_avg_percent = wyaralong_df['Last Observation (%)'].mean()\n",
    "\n",
    "atkinson_avg_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "43744ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2695.1</td>\n",
       "      <td>819941.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3115.1</td>\n",
       "      <td>946613.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1971.0</td>\n",
       "      <td>597556.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2073.0</td>\n",
       "      <td>628994.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2013.9</td>\n",
       "      <td>611992.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2274.5</td>\n",
       "      <td>691522.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Last Observation (%)  Last Observation (ML)\n",
       "Date                                             \n",
       "2017                2695.1              819941.37\n",
       "2018                3115.1              946613.40\n",
       "2019                1971.0              597556.10\n",
       "2020                2073.0              628994.20\n",
       "2021                2013.9              611992.25\n",
       "2022                2274.5              691522.53"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by year and calculate yearly totals\n",
    "\n",
    "atkinson_yearly_df = atkinson_df.groupby(atkinson_df['Date'].dt.to_period('Y')).sum()\n",
    "baroon_pocket_yearly_df = baroon_pocket_df.groupby(baroon_pocket_df['Date'].dt.to_period('Y')).sum()\n",
    "bill_gunn_year_df = bill_gunn_df.groupby(bill_gunn_df['Date'].dt.to_period('Y')).sum()\n",
    "borumba_year_df = borumba_df.groupby(borumba_df['Date'].dt.to_period('Y')).sum()\n",
    "clarendon_yearly_df = clarendon_df.groupby(clarendon_df['Date'].dt.to_period('Y')).sum()\n",
    "cooloolabin_yearly_df = cooloolabin_df.groupby(cooloolabin_df['Date'].dt.to_period('Y')).sum()\n",
    "enoggera_yearly_df = enoggera_df.groupby(enoggera_df['Date'].dt.to_period('Y')).sum()\n",
    "ewen_maddock_yearly_df = ewen_maddock_df.groupby(ewen_maddock_df['Date'].dt.to_period('Y')).sum()\n",
    "gold_creek_yearly_df = gold_creek_df.groupby(gold_creek_df['Date'].dt.to_period('Y')).sum()\n",
    "hinze_yearly_df = hinze_df.groupby(hinze_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_kurwongbah_yearly_df = lake_kurwongbah_df.groupby(lake_kurwongbah_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_macdonald_yearly_df = lake_macdonald_df.groupby(lake_macdonald_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_manchester_yearly_df = lake_manchester_df.groupby(lake_manchester_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_samsonvale_yearly_df = lake_samsonvale_df.groupby(lake_samsonvale_df['Date'].dt.to_period('Y')).sum()\n",
    "leslie_harrison_yearly_df = leslie_harrison_df.groupby(leslie_harrison_df['Date'].dt.to_period('Y')).sum()\n",
    "little_nerang_yearly_df = little_nerang_df.groupby(little_nerang_df['Date'].dt.to_period('Y')).sum()\n",
    "maroon_yearly_df = maroon_df.groupby(maroon_df['Date'].dt.to_period('Y')).sum()\n",
    "moogerah_yearly_df = moogerah_df.groupby(moogerah_df['Date'].dt.to_period('Y')).sum()\n",
    "nindooinbah_yearly_df = nindooinbah_df.groupby(nindooinbah_df['Date'].dt.to_period('Y')).sum()\n",
    "poona_yearly_df = poona_df.groupby(poona_df['Date'].dt.to_period('Y')).sum()\n",
    "seq_water_grid_yearly_df = seq_water_grid_df.groupby(seq_water_grid_df['Date'].dt.to_period('Y')).sum()\n",
    "somerset_yearly_df = somerset_df.groupby(somerset_df['Date'].dt.to_period('Y')).sum()\n",
    "wappa_yearly_df = wappa_df.groupby(wappa_df['Date'].dt.to_period('Y')).sum()\n",
    "wivenhoe_yearly_df = wivenhoe_df.groupby(wivenhoe_df['Date'].dt.to_period('Y')).sum()\n",
    "wyaralong_yearly_df = wyaralong_df.groupby(wyaralong_df['Date'].dt.to_period('Y')).sum()\n",
    "\n",
    "atkinson_yearly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "9c236242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>January</td>\n",
       "      <td>1765.6</td>\n",
       "      <td>536532.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February</td>\n",
       "      <td>1736.3</td>\n",
       "      <td>527489.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>March</td>\n",
       "      <td>1452.2</td>\n",
       "      <td>441609.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>April</td>\n",
       "      <td>1120.4</td>\n",
       "      <td>340611.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>May</td>\n",
       "      <td>997.9</td>\n",
       "      <td>303123.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>June</td>\n",
       "      <td>862.3</td>\n",
       "      <td>261946.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>July</td>\n",
       "      <td>819.0</td>\n",
       "      <td>248785.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August</td>\n",
       "      <td>858.5</td>\n",
       "      <td>260822.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>September</td>\n",
       "      <td>759.2</td>\n",
       "      <td>230506.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>October</td>\n",
       "      <td>928.9</td>\n",
       "      <td>282069.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>November</td>\n",
       "      <td>1118.4</td>\n",
       "      <td>339513.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>December</td>\n",
       "      <td>1723.9</td>\n",
       "      <td>523608.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Last Observation (%)  Last Observation (ML)\n",
       "4     January                1765.6              536532.00\n",
       "3    February                1736.3              527489.43\n",
       "7       March                1452.2              441609.58\n",
       "0       April                1120.4              340611.78\n",
       "8         May                 997.9              303123.78\n",
       "6        June                 862.3              261946.93\n",
       "5        July                 819.0              248785.46\n",
       "1      August                 858.5              260822.13\n",
       "11  September                 759.2              230506.13\n",
       "10    October                 928.9              282069.96\n",
       "9    November                1118.4              339513.87\n",
       "2    December                1723.9              523608.80"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by month and calculate monthly totals\n",
    "\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "atkinson_monthly_df = atkinson_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "atkinson_monthly_df.index = atkinson_monthly_df.index.strftime('%B')\n",
    "atkinson_monthly_df = atkinson_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "atkinson_monthly_df['Date'] = pd.Categorical(atkinson_monthly_df['Date'], month_order)\n",
    "atkinson_monthly_df = atkinson_monthly_df.sort_values('Date')\n",
    "\n",
    "baroon_pocket_monthly_df = baroon_pocket_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "baroon_pocket_monthly_df.index = baroon_pocket_monthly_df.index.strftime('%B')\n",
    "baroon_pocket_monthly_df = baroon_pocket_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "baroon_pocket_monthly_df['Date'] = pd.Categorical(baroon_pocket_monthly_df['Date'], month_order)\n",
    "baroon_pocket_monthly_df = baroon_pocket_monthly_df.sort_values('Date')\n",
    "\n",
    "bill_gunn_monthly_df = bill_gunn_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "bill_gunn_monthly_df.index = bill_gunn_monthly_df.index.strftime('%B')\n",
    "bill_gunn_monthly_df = bill_gunn_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "bill_gunn_monthly_df['Date'] = pd.Categorical(bill_gunn_monthly_df['Date'], month_order)\n",
    "bill_gunn_monthly_df = bill_gunn_monthly_df.sort_values('Date')\n",
    "\n",
    "borumba_monthly_df = borumba_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "borumba_monthly_df.index = borumba_monthly_df.index.strftime('%B')\n",
    "borumba_monthly_df = borumba_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "borumba_monthly_df['Date'] = pd.Categorical(borumba_monthly_df['Date'], month_order)\n",
    "borumba_monthly_df = borumba_monthly_df.sort_values('Date')\n",
    "\n",
    "cedar_pocket_monthly_df = cedar_pocket_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "cedar_pocket_monthly_df.index = cedar_pocket_monthly_df.index.strftime('%B')\n",
    "cedar_pocket_monthly_df = cedar_pocket_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "cedar_pocket_monthly_df['Date'] = pd.Categorical(cedar_pocket_monthly_df['Date'], month_order)\n",
    "cedar_pocket_monthly_df = cedar_pocket_monthly_df.sort_values('Date')\n",
    "\n",
    "clarendon_monthly_df = clarendon_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "clarendon_monthly_df.index = clarendon_monthly_df.index.strftime('%B')\n",
    "clarendon_monthly_df = clarendon_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "clarendon_monthly_df['Date'] = pd.Categorical(clarendon_monthly_df['Date'], month_order)\n",
    "clarendon_monthly_df = clarendon_monthly_df.sort_values('Date')\n",
    "\n",
    "cooloolabin_monthly_df = cooloolabin_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "cooloolabin_monthly_df.index = cooloolabin_monthly_df.index.strftime('%B')\n",
    "cooloolabin_monthly_df = cooloolabin_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "cooloolabin_monthly_df['Date'] = pd.Categorical(cooloolabin_monthly_df['Date'], month_order)\n",
    "cooloolabin_monthly_df = cooloolabin_monthly_df.sort_values('Date')\n",
    "\n",
    "enoggera_monthly_df = enoggera_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "enoggera_monthly_df.index = enoggera_monthly_df.index.strftime('%B')\n",
    "enoggera_monthly_df = enoggera_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "enoggera_monthly_df['Date'] = pd.Categorical(enoggera_monthly_df['Date'], month_order)\n",
    "enoggera_monthly_df = enoggera_monthly_df.sort_values('Date')\n",
    "\n",
    "ewen_maddock_monthly_df = ewen_maddock_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "ewen_maddock_monthly_df.index = ewen_maddock_monthly_df.index.strftime('%B')\n",
    "ewen_maddock_monthly_df = ewen_maddock_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "ewen_maddock_monthly_df['Date'] = pd.Categorical(ewen_maddock_monthly_df['Date'], month_order)\n",
    "ewen_maddock_monthly_df = ewen_maddock_monthly_df.sort_values('Date')\n",
    "\n",
    "gold_creek_monthly_df = gold_creek_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "gold_creek_monthly_df.index = gold_creek_monthly_df.index.strftime('%B')\n",
    "gold_creek_monthly_df = gold_creek_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "gold_creek_monthly_df['Date'] = pd.Categorical(gold_creek_monthly_df['Date'], month_order)\n",
    "gold_creek_monthly_df = gold_creek_monthly_df.sort_values('Date')\n",
    "\n",
    "hinze_monthly_df = hinze_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "hinze_monthly_df.index = hinze_monthly_df.index.strftime('%B')\n",
    "hinze_monthly_df = hinze_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "hinze_monthly_df['Date'] = pd.Categorical(hinze_monthly_df['Date'], month_order)\n",
    "hinze_monthly_df = hinze_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_kurwongbah_monthly_df.index = lake_kurwongbah_monthly_df.index.strftime('%B')\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_kurwongbah_monthly_df['Date'] = pd.Categorical(lake_kurwongbah_monthly_df['Date'], month_order)\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_macdonald_monthly_df = lake_macdonald_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_macdonald_monthly_df.index = lake_macdonald_monthly_df.index.strftime('%B')\n",
    "lake_macdonald_monthly_df = lake_macdonald_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_macdonald_monthly_df['Date'] = pd.Categorical(lake_macdonald_monthly_df['Date'], month_order)\n",
    "lake_macdonald_monthly_df = lake_macdonald_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_manchester_monthly_df = lake_manchester_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_manchester_monthly_df.index = lake_manchester_monthly_df.index.strftime('%B')\n",
    "lake_manchester_monthly_df = lake_manchester_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_manchester_monthly_df['Date'] = pd.Categorical(lake_manchester_monthly_df['Date'], month_order)\n",
    "lake_manchester_monthly_df = lake_manchester_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_samsonvale_monthly_df = lake_samsonvale_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_samsonvale_monthly_df.index = lake_samsonvale_monthly_df.index.strftime('%B')\n",
    "lake_samsonvale_monthly_df = lake_samsonvale_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_samsonvale_monthly_df['Date'] = pd.Categorical(lake_samsonvale_monthly_df['Date'], month_order)\n",
    "lake_samsonvale_monthly_df = lake_samsonvale_monthly_df.sort_values('Date')\n",
    "\n",
    "leslie_harrison_monthly_df = leslie_harrison_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "leslie_harrison_monthly_df.index = leslie_harrison_monthly_df.index.strftime('%B')\n",
    "leslie_harrison_monthly_df = leslie_harrison_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "leslie_harrison_monthly_df['Date'] = pd.Categorical(leslie_harrison_monthly_df['Date'], month_order)\n",
    "leslie_harrison_monthly_df = leslie_harrison_monthly_df.sort_values('Date')\n",
    "\n",
    "little_nerang_monthly_df = little_nerang_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "little_nerang_monthly_df.index = little_nerang_monthly_df.index.strftime('%B')\n",
    "little_nerang_monthly_df = little_nerang_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "little_nerang_monthly_df['Date'] = pd.Categorical(little_nerang_monthly_df['Date'], month_order)\n",
    "little_nerang_monthly_df = little_nerang_monthly_df.sort_values('Date')\n",
    "\n",
    "maroon_monthly_df = maroon_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "maroon_monthly_df.index = maroon_monthly_df.index.strftime('%B')\n",
    "maroon_monthly_df = lake_macdonald_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "maroon_monthly_df['Date'] = pd.Categorical(maroon_monthly_df['Date'], month_order)\n",
    "maroon_monthly_df = maroon_monthly_df.sort_values('Date')\n",
    "\n",
    "moogerah_monthly_df = moogerah_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "moogerah_monthly_df.index = moogerah_monthly_df.index.strftime('%B')\n",
    "moogerah_monthly_df = moogerah_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "moogerah_monthly_df['Date'] = pd.Categorical(moogerah_monthly_df['Date'], month_order)\n",
    "moogerah_monthly_df = moogerah_monthly_df.sort_values('Date')\n",
    "\n",
    "nindooinbah_monthly_df = nindooinbah_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "nindooinbah_monthly_df.index = nindooinbah_monthly_df.index.strftime('%B')\n",
    "nindooinbah_monthly_df = nindooinbah_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "nindooinbah_monthly_df['Date'] = pd.Categorical(nindooinbah_monthly_df['Date'], month_order)\n",
    "nindooinbah_monthly_df = nindooinbah_monthly_df.sort_values('Date')\n",
    "\n",
    "poona_monthly_df = poona_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "poona_monthly_df.index = poona_monthly_df.index.strftime('%B')\n",
    "poona_monthly_df = poona_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "poona_monthly_df['Date'] = pd.Categorical(poona_monthly_df['Date'], month_order)\n",
    "poona_monthly_df = poona_monthly_df.sort_values('Date')\n",
    "\n",
    "seq_water_grid_monthly_df = seq_water_grid_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "seq_water_grid_monthly_df.index = seq_water_grid_monthly_df.index.strftime('%B')\n",
    "seq_water_grid_monthly_df = seq_water_grid_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "seq_water_grid_monthly_df['Date'] = pd.Categorical(seq_water_grid_monthly_df['Date'], month_order)\n",
    "seq_water_grid_monthly_df = seq_water_grid_monthly_df.sort_values('Date')\n",
    "\n",
    "somerset_monthly_df = somerset_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "somerset_monthly_df.index = somerset_monthly_df.index.strftime('%B')\n",
    "somerset_monthly_df = somerset_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "somerset_monthly_df['Date'] = pd.Categorical(somerset_monthly_df['Date'], month_order)\n",
    "somerset_monthly_df = somerset_monthly_df.sort_values('Date')\n",
    "\n",
    "wappa_monthly_df = wappa_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "wappa_monthly_df.index = wappa_monthly_df.index.strftime('%B')\n",
    "wappa_monthly_df = wappa_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "wappa_monthly_df['Date'] = pd.Categorical(wappa_monthly_df['Date'], month_order)\n",
    "wappa_monthly_df = wappa_monthly_df.sort_values('Date')\n",
    "\n",
    "wyaralong_monthly_df = wyaralong_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "wyaralong_monthly_df.index = wyaralong_monthly_df.index.strftime('%B')\n",
    "wyaralong_monthly_df = wyaralong_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "wyaralong_monthly_df['Date'] = pd.Categorical(wyaralong_monthly_df['Date'], month_order)\n",
    "wyaralong_monthly_df = wyaralong_monthly_df.sort_values('Date')\n",
    "\n",
    "atkinson_monthly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb949fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot - Dam Volume/Capacity\n",
    "\n",
    "# Font families\n",
    "font_1 = {'family':'helvetica','color':'black','size':16}\n",
    "font_2 = {'family':'helvetica','color':'black','size':12}\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(seq_water_grid_df['Date'], seq_water_grid_df['Last Observation (%)'], color=\"blue\", markersize='7', \n",
    "         linewidth=2)\n",
    "#plt.bar(seq_water_grid_df['Date'], seq_water_grid_df['Last Observation (%)'], width=0.5, color='blue', alpha=0.5)\n",
    "\n",
    "plt.title('SEQ rainwater catchment levels, April 2017 â€“ March 2022', fontdict = font_1)\n",
    "plt.xlabel('Year', fontdict = font_2)\n",
    "plt.ylabel('Volume/Capacity (%)', fontdict = font_2)\n",
    "#plt.legend()\n",
    "\n",
    "# Aesthetics\n",
    "\n",
    "matplotlib.pyplot.grid(visible=True, which='both', axis='both', \n",
    "                       color='blue', alpha=0.1, dash_capstyle='butt', dash_joinstyle='bevel', \n",
    "                       linestyle='--', linewidth=1)\n",
    "\n",
    "# interest_rates_df.plot(ax=ax, x_compat=True)\n",
    "\n",
    "# ax.xaxis.set_major_locator(matplotlibdates.YearLocator(base=1))\n",
    "# ax.xaxis.set_major_formatter(matplotlibdates.DateFormatter(\"%Y\"))\n",
    "        \n",
    "        \n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show/save\n",
    "#plt.savefig(\"/Users/minoperic/Data Analytics/Data Investigations/australian-interest-rates/Images/comparison.png\", \n",
    "            #transparent=False, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages by decade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
